{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SediNet_Continuous_SievedSand_9Prcs.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Mmv6E4xVrPKH","colab_type":"text"},"source":["## Sedinet: predict 9 percentiles of the grain size distribution from a small population of beach sands"]},{"cell_type":"markdown","metadata":{"id":"9q6xzJ6hrUSP","colab_type":"text"},"source":["This Jupyter notebook accompanies the [SediNet](https://github.com/MARDAScience/SediNet) package\n","\n","Written by Daniel Buscombe, MARDA Science\n","\n","daniel@mardascience.com\n","\n","\n","> Demonstration of how to use SediNet to estimate from an ensemble of three models to estimate nine percentiles of the cumulative grain size distribution from a population of beach sands\n","\n","First, this notebbok assumes you are a cloud computer such as Colab so we first download the SediNet package from github:\n"]},{"cell_type":"code","metadata":{"id":"gHs5dUy8sxM-","colab_type":"code","outputId":"4fe3c6b1-c5ff-4cb9-9dd1-282832ba0db5","executionInfo":{"status":"ok","timestamp":1564424134394,"user_tz":420,"elapsed":1902,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["!git clone --depth 1 https://github.com/MARDAScience/SediNet.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["fatal: destination path 'SediNet' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"91QV0zqztBZD","colab_type":"code","colab":{}},"source":["import os, json\n","os.chdir('SediNet')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I9YJKEa3sxVG","colab_type":"text"},"source":["Import everything we need from sedinet_models.py"]},{"cell_type":"code","metadata":{"id":"1oi9C5Hcqsjh","colab_type":"code","outputId":"c156caac-36b7-4534-f8ca-0bc23aecaa8d","executionInfo":{"status":"ok","timestamp":1564424141808,"user_tz":420,"elapsed":2684,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sedinet_models import *"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ZftisMCWrCxy","colab_type":"code","colab":{}},"source":["configfile = 'config_sievedsand_9prcs.json'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I_opHDLcrLpW","colab_type":"text"},"source":["Load the config file and parse out the variables we need"]},{"cell_type":"code","metadata":{"id":"GjskF4hBrL1C","colab_type":"code","colab":{}},"source":["# load the user configs\n","with open(os.getcwd()+os.sep+'config'+os.sep+configfile) as f:    \n","  config = json.load(f)     \n","\n","###===================================================\n","## user defined variables: proportion of data to use for training (a.k.a. the \"train/test split\")\n","base    = int(config[\"base\"]) #minimum number of convolutions in a sedinet convolutional block\n","csvfile = config[\"csvfile\"] #csvfile containing image names and class values\n","res_folder = config[\"res_folder\"] #folder containing csv file and that will contain model outputs\n","name = config[\"name\"] #name prefix for output files\n","dropout = float(config[\"dropout\"]) \n","add_bn = bool(config[\"add_bn\"]) \n","\n","vars = [k for k in config.keys() if not np.any([k.startswith('base'), k.startswith('res_folder'), k.startswith('csvfile'), k.startswith('name'), k.startswith('dropout'), k.startswith('add_bn')])]\n","\n","vars = sorted(vars)\n","\n","###==================================================\n","\n","csvfile = res_folder+os.sep+csvfile"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xht-WH_4rTqZ","colab_type":"text"},"source":["This next part reads the data in from the csv file as a pandas dataframe, gets an image generator, and then prepares three models with different base values"]},{"cell_type":"code","metadata":{"id":"WuLSL_Narm41","colab_type":"code","colab":{}},"source":["###===================================================\n","## read the data set in, clean and modify the pathnames so they are absolute\n","df = pd.read_csv(csvfile)\n","df['files'] = [k.strip() for k in df['files']]\n","df['files'] = [os.getcwd()+os.sep+f.replace('\\\\',os.sep) for f in df['files']]    \n","\n","train_idx = np.arange(len(df))\n","\n","##==============================================\n","## create training and testing file generators, set the weights path, plot the model, and create a callback list for model training   \n","if len(vars)==1:        \n","  train_gen = get_data_generator_1vars(df, train_idx, True, vars, len(df))\n","elif len(vars)==2:        \n","  train_gen = get_data_generator_2vars(df, train_idx, True, vars, len(df))\n","elif len(vars)==3:        \n","  train_gen = get_data_generator_3vars(df, train_idx, True, vars, len(df))\n","elif len(vars)==4:        \n","  train_gen = get_data_generator_4vars(df, train_idx, True, vars, len(df))\n","elif len(vars)==5:        \n","  train_gen = get_data_generator_5vars(df, train_idx, True, vars, len(df))\n","elif len(vars)==6:        \n","  train_gen = get_data_generator_6vars(df, train_idx, True, vars, len(df))\n","elif len(vars)==7:        \n","  train_gen = get_data_generator_7vars(df, train_idx, True, vars, len(df))\n","elif len(vars)==8:        \n","  train_gen = get_data_generator_8vars(df, train_idx, True, vars, len(df))\n","elif len(vars)==9:        \n","  train_gen = get_data_generator_9vars(df, train_idx, True, vars, len(df))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-UVpFDG6xIR","colab_type":"code","outputId":"eb5a2903-ff28-47fc-d695-dd6f9f6168cc","executionInfo":{"status":"ok","timestamp":1564424175243,"user_tz":420,"elapsed":7678,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["x_train, tmp = next(train_gen)   \n","if len(vars)>1:    \n","  counter = 0\n","  for v in vars:\n","     exec(v+'_trueT = np.squeeze(tmp[counter])')\n","     counter +=1\n","else:\n","  exec(vars[0]+'_trueT = np.squeeze(tmp)')\n","\n","models = []\n","for base in [base-2,base,base+2]:\n","  weights_path = name+\"_base\"+str(base)+\"_model_checkpoint.hdf5\"\n","  ##==============================================\n","  ## create a SediNet model to estimate sediment category\n","  model = make_cont_sedinet(base, vars, add_bn, dropout)\n","  model.load_weights(os.getcwd()+os.sep+'res'+os.sep+res_folder+os.sep+weights_path)\n","  models.append(model)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0729 18:16:12.752464 139654820411264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0729 18:16:12.767957 139654820411264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0729 18:16:12.773661 139654820411264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0729 18:16:12.805110 139654820411264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","W0729 18:16:12.849107 139654820411264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0729 18:16:12.850326 139654820411264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","W0729 18:16:12.907191 139654820411264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","W0729 18:16:12.990581 139654820411264 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0729 18:16:13.125216 139654820411264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["==========================================\n","[INFORMATION] Model summary:\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 512, 1024, 1) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 510, 1022, 22 220         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 508, 1020, 44 8756        conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 254, 510, 44) 0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 252, 508, 66) 26202       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 126, 254, 66) 0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 124, 252, 88) 52360       max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 62, 126, 88)  0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 62, 126, 88)  352         max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","global_max_pooling2d_1 (GlobalM (None, 88)           0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 88)           0           global_max_pooling2d_1[0][0]     \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 512)          45568       dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","P10_output (Dense)              (None, 1)            513         dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","P16_output (Dense)              (None, 1)            513         dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","P25_output (Dense)              (None, 1)            513         dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","P5_output (Dense)               (None, 1)            513         dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","P50_output (Dense)              (None, 1)            513         dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","P75_output (Dense)              (None, 1)            513         dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","P84_output (Dense)              (None, 1)            513         dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","P90_output (Dense)              (None, 1)            513         dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","P95_output (Dense)              (None, 1)            513         dense_1[0][0]                    \n","==================================================================================================\n","Total params: 138,075\n","Trainable params: 137,899\n","Non-trainable params: 176\n","__________________________________________________________________________________________________\n","==========================================\n","[INFORMATION] Model summary:\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 512, 1024, 1) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 510, 1022, 24 240         input_2[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 508, 1020, 48 10416       conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_4 (MaxPooling2D)  (None, 254, 510, 48) 0           conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 252, 508, 72) 31176       max_pooling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_5 (MaxPooling2D)  (None, 126, 254, 72) 0           conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 124, 252, 96) 62304       max_pooling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_6 (MaxPooling2D)  (None, 62, 126, 96)  0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 62, 126, 96)  384         max_pooling2d_6[0][0]            \n","__________________________________________________________________________________________________\n","global_max_pooling2d_2 (GlobalM (None, 96)           0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 96)           0           global_max_pooling2d_2[0][0]     \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 512)          49664       dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","P10_output (Dense)              (None, 1)            513         dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","P16_output (Dense)              (None, 1)            513         dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","P25_output (Dense)              (None, 1)            513         dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","P5_output (Dense)               (None, 1)            513         dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","P50_output (Dense)              (None, 1)            513         dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","P75_output (Dense)              (None, 1)            513         dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","P84_output (Dense)              (None, 1)            513         dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","P90_output (Dense)              (None, 1)            513         dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","P95_output (Dense)              (None, 1)            513         dense_2[0][0]                    \n","==================================================================================================\n","Total params: 158,801\n","Trainable params: 158,609\n","Non-trainable params: 192\n","__________________________________________________________________________________________________\n","==========================================\n","[INFORMATION] Model summary:\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            (None, 512, 1024, 1) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 510, 1022, 26 260         input_3[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 508, 1020, 52 12220       conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_7 (MaxPooling2D)  (None, 254, 510, 52) 0           conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 252, 508, 78) 36582       max_pooling2d_7[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_8 (MaxPooling2D)  (None, 126, 254, 78) 0           conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 124, 252, 104 73112       max_pooling2d_8[0][0]            \n","__________________________________________________________________________________________________\n","max_pooling2d_9 (MaxPooling2D)  (None, 62, 126, 104) 0           conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 62, 126, 104) 416         max_pooling2d_9[0][0]            \n","__________________________________________________________________________________________________\n","global_max_pooling2d_3 (GlobalM (None, 104)          0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 104)          0           global_max_pooling2d_3[0][0]     \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 512)          53760       dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","P10_output (Dense)              (None, 1)            513         dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","P16_output (Dense)              (None, 1)            513         dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","P25_output (Dense)              (None, 1)            513         dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","P5_output (Dense)               (None, 1)            513         dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","P50_output (Dense)              (None, 1)            513         dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","P75_output (Dense)              (None, 1)            513         dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","P84_output (Dense)              (None, 1)            513         dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","P90_output (Dense)              (None, 1)            513         dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","P95_output (Dense)              (None, 1)            513         dense_3[0][0]                    \n","==================================================================================================\n","Total params: 180,967\n","Trainable params: 180,759\n","Non-trainable params: 208\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Dwz1HlwcsJj4","colab_type":"text"},"source":["Now the models are set up, we use them below to make predictions on each image so we end up with three estimates per image, and our final estimate is their mean"]},{"cell_type":"code","metadata":{"id":"VCphNJ-JsJux","colab_type":"code","colab":{}},"source":["for v in vars:\n","  exec(v+'_PT = []')\n","#PT = []      \n","for model in models:   \n","  tmp = model.predict(x_train, batch_size=1)\n","  if len(vars)>1:    \n","     counter = 0\n","     for v in vars:\n","        exec(v+'_PT.append(np.squeeze(tmp[counter]))')\n","        counter +=1\n","  else:\n","     exec(vars[0]+'_PT.append(np.asarray(np.squeeze(tmp)))') #.argmax(axis=-1))')\n","\n","if len(vars)>1:\n","  for k in range(len(vars)):  \n","     exec(vars[k]+'_predT = np.squeeze(np.mean(np.asarray('+vars[k]+'_PT), axis=0))')\n","else:   \n","  exec(vars[0]+'_predT = np.squeeze(np.mean(np.asarray('+vars[0]+'_PT), axis=0))')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AAmUYcofsE3E","colab_type":"text"},"source":["Finally we print a confusion matrix showing normalized  correspondences between actual and estimated labels"]},{"cell_type":"code","metadata":{"id":"rww4YXcysFAz","colab_type":"code","colab":{}},"source":["if len(vars)==9:    \n","  nrows = 3; ncols = 3\n","elif len(vars)==8:    \n","  nrows = 4; ncols = 2\n","elif len(vars)==7:    \n","  nrows = 4; ncols = 2           \n","elif len(vars)==6:    \n","  nrows = 3; ncols = 2\n","elif len(vars)==5:    \n","  nrows = 3; ncols = 2       \n","elif len(vars)==4:    \n","  nrows = 2; ncols = 2       \n","elif len(vars)==3:    \n","  nrows = 3; ncols = 1      \n","elif len(vars)==2:    \n","  nrows = 2; ncols = 1      \n","elif len(vars)==1:    \n","  nrows = 1; ncols = 1\n","\n","## make a plot                  \n","fig = plt.figure(figsize=(4*nrows,4*ncols))\n","labs = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n","for k in range(1,1+(nrows*ncols)):\n","  plt.subplot(nrows,ncols,k)\n","  plt.plot(eval(vars[k-1]+'_trueT'), eval(vars[k-1]+'_predT'), 'ko', markersize=3)\n","  #plt.plot(eval(vars[k-1]+'_true'), eval(vars[k-1]+'_pred'), 'bx', markersize=5)\n","  plt.plot([5, 1000], [5, 1000], 'k', lw=2)\n","  plt.xscale('log'); plt.yscale('log')\n","  #plt.text(11,700,'Test : '+str(np.mean(100*(np.abs(eval(vars[k-1]+'_pred') - eval(vars[k-1]+'_true')) / eval(vars[k-1]+'_true'))))[:5]+' %',  fontsize=8, color='b')\n","  plt.text(11,1000,'Train : '+str(np.mean(100*(np.abs(eval(vars[k-1]+'_predT') - eval(vars[k-1]+'_trueT')) / eval(vars[k-1]+'_trueT'))))[:5]+' %', fontsize=8)\n","  plt.xlim(10,1300); plt.ylim(10,1300)\n","  plt.title(r''+labs[k-1]+') '+vars[k-1], fontsize=8, loc='left')\n","\n","#plt.show()\n","plt.savefig(name+str(IM_HEIGHT)+'_batch'+str(batch_size)+'_xy-base'+str(base)+'_predict.png', dpi=300, bbox_inches='tight')\n","plt.close()\n","del fig  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8lggiKFIvfGY","colab_type":"text"},"source":["If you are in Google Colab, to view the file you just made, go to tn the File tab over on the left, expand SediNet, and you'll see the png file called \"sievesand_9prcs_xxxx-predict.png\""]}]}