{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SediNet_Categorical_Pop.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Mmv6E4xVrPKH","colab_type":"text"},"source":["## Sedinet: predict categorical population"]},{"cell_type":"markdown","metadata":{"id":"9q6xzJ6hrUSP","colab_type":"text"},"source":["This Jupyter notebook accompanies the [SediNet](https://github.com/MARDAScience/SediNet) package\n","\n","Written by Daniel Buscombe, MARDA Science\n","\n","daniel@mardascience.com\n","\n","\n","> Demonstration of how to use SediNet to estimate from an ensemble of three models to estimate sediment population\n","\n","First, this notebbok assumes you are a cloud computer such as Colab so we first download the SediNet package from github:\n"]},{"cell_type":"code","metadata":{"id":"gHs5dUy8sxM-","colab_type":"code","outputId":"55a217ff-fba5-42b1-dc33-d499ce437db4","executionInfo":{"status":"ok","timestamp":1564421877217,"user_tz":420,"elapsed":1423,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["!git clone --depth 1 https://github.com/MARDAScience/SediNet.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["fatal: destination path 'SediNet' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"91QV0zqztBZD","colab_type":"code","colab":{}},"source":["import os, json\n","os.chdir('SediNet')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I9YJKEa3sxVG","colab_type":"text"},"source":["Import everything we need from sedinet_models.py"]},{"cell_type":"code","metadata":{"id":"1oi9C5Hcqsjh","colab_type":"code","outputId":"31dd021b-2b04-477b-9fb4-c00c3d448944","executionInfo":{"status":"ok","timestamp":1564421885463,"user_tz":420,"elapsed":2299,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sedinet_models import *"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ZftisMCWrCxy","colab_type":"code","colab":{}},"source":["configfile = 'config_pop.json'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I_opHDLcrLpW","colab_type":"text"},"source":["Load the config file and parse out the variables we need"]},{"cell_type":"code","metadata":{"id":"GjskF4hBrL1C","colab_type":"code","colab":{}},"source":["# load the user configs\n","with open(os.getcwd()+os.sep+'config'+os.sep+configfile) as f:    \n","  config = json.load(f)     \n","\n","###===================================================\n","## user defined variables: proportion of data to use for training (a.k.a. the \"train/test split\")\n","base    = int(config[\"base\"]) #minimum number of convolutions in a sedinet convolutional block\n","csvfile = config[\"csvfile\"] #csvfile containing image names and class values\n","res_folder = config[\"res_folder\"] #folder containing csv file and that will contain model outputs\n","var = config[\"var\"] # column name in the csv you wish to estimate\n","numclass = config[\"numclass\"] # number of classes\n","dropout = float(config[\"dropout\"]) \n","\n","###==================================================\n","ID_MAP = dict(zip(np.arange(numclass), [str(k) for k in range(numclass)]))\n","csvfile = res_folder+os.sep+csvfile"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xht-WH_4rTqZ","colab_type":"text"},"source":["This next part reads the data in from the csv file as a pandas dataframe, gets an image generator, and then prepares three models with different base values"]},{"cell_type":"code","metadata":{"id":"WuLSL_Narm41","colab_type":"code","outputId":"fefc0168-28ab-42ec-861e-719ef49b14ae","executionInfo":{"status":"ok","timestamp":1564421890023,"user_tz":420,"elapsed":1125,"user":{"displayName":"Daniel Buscombe","photoUrl":"","userId":"01832231008732716345"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["###===================================================\n","## read the data set in, clean and modify the pathnames so they are absolute\n","df = pd.read_csv(csvfile)\n","df['files'] = [k.strip() for k in df['files']]\n","df['files'] = [os.getcwd()+os.sep+f.replace('\\\\',os.sep) for f in df['files']]    \n","\n","train_idx = np.arange(len(df))\n","\n","train_gen = get_data_generator_1image(df, train_idx, True, ID_MAP, var, len(df))\n","\n","models = []\n","for base in [base-2,base,base+2]:\n","  weights_path = var+\"_base\"+str(base)+\"_model_checkpoint.hdf5\"\n","  ##==============================================\n","  ## create a SediNet model to estimate sediment category\n","  model = make_cat_sedinet(base, ID_MAP, dropout)\n","  model.load_weights(os.getcwd()+os.sep+'res'+os.sep+res_folder+os.sep+weights_path)\n","  models.append(model)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0729 17:38:08.879631 140230332524416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0729 17:38:08.895930 140230332524416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0729 17:38:08.900372 140230332524416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0729 17:38:08.929696 140230332524416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","W0729 17:38:08.962562 140230332524416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0729 17:38:08.972671 140230332524416 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0729 17:38:09.015380 140230332524416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0729 17:38:09.039649 140230332524416 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["==========================================\n","[INFORMATION] Model summary:\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 512, 512, 3)       0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 510, 510, 18)      504       \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 508, 508, 36)      5868      \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 254, 254, 36)      0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 252, 252, 54)      17550     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 126, 126, 54)      0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 124, 124, 72)      35064     \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 62, 62, 72)        0         \n","_________________________________________________________________\n","global_max_pooling2d_1 (Glob (None, 72)                0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 72)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 128)               9344      \n","_________________________________________________________________\n","output (Dense)               (None, 6)                 774       \n","=================================================================\n","Total params: 69,104\n","Trainable params: 69,104\n","Non-trainable params: 0\n","_________________________________________________________________\n","==========================================\n","[INFORMATION] Model summary:\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         (None, 512, 512, 3)       0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 510, 510, 20)      560       \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 508, 508, 40)      7240      \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 254, 254, 40)      0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 252, 252, 60)      21660     \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 126, 126, 60)      0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 124, 124, 80)      43280     \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 62, 62, 80)        0         \n","_________________________________________________________________\n","global_max_pooling2d_2 (Glob (None, 80)                0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 80)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 128)               10368     \n","_________________________________________________________________\n","output (Dense)               (None, 6)                 774       \n","=================================================================\n","Total params: 83,882\n","Trainable params: 83,882\n","Non-trainable params: 0\n","_________________________________________________________________\n","==========================================\n","[INFORMATION] Model summary:\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 512, 512, 3)       0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 510, 510, 22)      616       \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 508, 508, 44)      8756      \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 254, 254, 44)      0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 252, 252, 66)      26202     \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 126, 126, 66)      0         \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 124, 124, 88)      52360     \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 62, 62, 88)        0         \n","_________________________________________________________________\n","global_max_pooling2d_3 (Glob (None, 88)                0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 88)                0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 128)               11392     \n","_________________________________________________________________\n","output (Dense)               (None, 6)                 774       \n","=================================================================\n","Total params: 100,100\n","Trainable params: 100,100\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Dwz1HlwcsJj4","colab_type":"text"},"source":["Now the models are set up, we use them below to make predictions on each image so we end up with three estimates per image, and our final estimate is their mode\n","\n","A classification report is printed to screen showing per-class F1 scores which is an average of precision and recall. Precision is the proportion of positive identifications that are correct (a precision of 1 means there are no false positives), and recall is the proportion of actual positives identified correctly (a recall of 1 means there are no false negatives). "]},{"cell_type":"code","metadata":{"id":"VCphNJ-JsJux","colab_type":"code","colab":{}},"source":["x_train, (trueT)= next(train_gen) \n","trueT = np.squeeze(np.asarray(trueT).argmax(axis=-1) )\n","\n","P = []; PT = []      \n","for model in models:   \n","  predT = model.predict(x_train, batch_size=1) \n","  predT = np.asarray(predT).argmax(axis=-1)      \n","  PT.append(predT)\n","\n","predT = np.squeeze(mode(np.asarray(PT), axis=0)[0])\n","\n","##==============================================\n","## print a classification report to screen, showing f1, precision, recall and accuracy\n","print(\"==========================================\")\n","print(\"Classification report for \"+var)\n","print(classification_report(trueT, predT))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AAmUYcofsE3E","colab_type":"text"},"source":["Finally we print a confusion matrix showing normalized  correspondences between actual and estimated labels"]},{"cell_type":"code","metadata":{"id":"rww4YXcysFAz","colab_type":"code","colab":{}},"source":["classes = np.arange(len(ID_MAP))\n","##==============================================\n","## create figures showing confusion matrices for data set\n","plot_confmat(predT, trueT, var+'T',classes)  \n","plt.savefig(weights_path.replace('.hdf5','_cm_predict.png'), dpi=300, bbox_inches='tight') \n","plt.close('all')   "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8lggiKFIvfGY","colab_type":"text"},"source":["If you are in Google Colab, to view the file you just made, go to tn the File tab over on the left, expand SediNet, and you'll see the png file called \"pop_base22_xxxx.png\""]},{"cell_type":"code","metadata":{"id":"dBGWBO330EvN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}